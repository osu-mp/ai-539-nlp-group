{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osu-mp/ai-539-nlp-group/blob/main/SparsityCheckCondaColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDL0pt0ai5TQ",
        "outputId": "ccaaab3d-7b95-4e98-8a0d-7a8e5b71f3a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:32\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import condacolab\n",
        "condacolab.check()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfJYYS6ii8W9",
        "outputId": "b16829d6-6b1a-4dc5-b465-d5aa6dcf8908"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ¨ðŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive')\n",
        "import sys\n",
        "from google.colab import drive\n",
        "sys.path.append(GOOGLE_DRIVE_PATH)\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ze-PaFyjBqP",
        "outputId": "85011ce8-e97e-4615-e67d-c70bf6ebda9c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ],
      "metadata": {
        "id": "hQ4GuLsPjiE9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conda_path = ''\n",
        "try:\n",
        "    conda_path = !which conda\n",
        "finally:\n",
        "    print('')\n",
        "\n",
        "if (len(conda_path) == 0):\n",
        "    print('installing miniconda')\n",
        "    !wget https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh && bash Miniconda3-4.5.4-Linux-x86_64.sh -bfp /usr/local\n",
        "    !conda update conda -y -q\n",
        "    !source /usr/local/etc/profile.d/conda.sh\n",
        "    !conda init \n",
        "    !conda install -n root _license -y -q\n",
        "else:\n",
        "    print('found miniconda')\n",
        "\n",
        "conda_envs = !conda env list\n",
        "res = [i for i in conda_envs if 'test38' in i]\n",
        "if (len(res) == 0):\n",
        "    print('not found test38 env', len(res))\n",
        "    !conda create -y -q --name test38 python=3.8\n",
        "else:\n",
        "    print('found test38 env', len(res))\n",
        "\n",
        "#!conda env update -n base -f '/content/drive/MyDrive/AI539MUSSLT/environment.yml'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ybj_HJljEHF",
        "outputId": "4546f65f-c8cd-4d3f-d56d-4fa2661b0f33"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "found miniconda\n",
            "not found test38 env 0\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/test38\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.8\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    openssl-3.1.0              |       h0b41bf4_0         2.5 MB  conda-forge\n",
            "    python-3.8.16              |he550d4f_1_cpython        21.8 MB  conda-forge\n",
            "    setuptools-67.6.0          |     pyhd8ed1ab_0         566 KB  conda-forge\n",
            "    wheel-0.40.0               |     pyhd8ed1ab_0          54 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        24.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h7f98852_4 \n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2022.12.7-ha878542_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.40-h41732ed_0 \n",
            "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-12.2.0-h65d4601_19 \n",
            "  libgomp            conda-forge/linux-64::libgomp-12.2.0-h65d4601_19 \n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.0-h7f98852_0 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.40.0-h753d276_0 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.2.13-h166bdaf_4 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.3-h27087fc_1 \n",
            "  openssl            conda-forge/linux-64::openssl-3.1.0-h0b41bf4_0 \n",
            "  pip                conda-forge/noarch::pip-23.0.1-pyhd8ed1ab_0 \n",
            "  python             conda-forge/linux-64::python-3.8.16-he550d4f_1_cpython \n",
            "  readline           conda-forge/linux-64::readline-8.1.2-h0f457ee_0 \n",
            "  setuptools         conda-forge/noarch::setuptools-67.6.0-pyhd8ed1ab_0 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.12-h27826a3_0 \n",
            "  wheel              conda-forge/noarch::wheel-0.40.0-pyhd8ed1ab_0 \n",
            "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0 \n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate test38\n",
        "\n",
        "python\n",
        "import sys\n",
        "# maybe only need this the first time we run this notebook\n",
        "sys.path.append('/usr/local/lib/python3.8/site-packages')\n",
        "\n",
        "print(\"Python version\")\n",
        "print(sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCYsbkI8qOlu",
        "outputId": "977725e7-8630-4b73-9fac-2ac69f722d6b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version\n",
            "3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55) \n",
            "[GCC 11.3.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env update -n test38 -f '/content/drive/MyDrive/AI539MUSSLT/environment.yml'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58ZMeGGNqT9X",
        "outputId": "6a507217-7413-4b99-f306-21835fc7d267"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 22.11.1\n",
            "  latest version: 23.1.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "Or to minimize the number of packages updated during conda update use\n",
            "\n",
            "     conda install conda=23.1.0\n",
            "\n",
            "\n",
            "Installing pip dependencies: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ Ran pip subprocess with arguments:\n",
            "['/usr/local/envs/test38/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt', '--exists-action=b']\n",
            "Pip subprocess output:\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting antlr4-python3-runtime==4.9.3\n",
            "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
            "Collecting bayesian-optimization==1.4.2\n",
            "  Using cached bayesian_optimization-1.4.2-py3-none-any.whl (17 kB)\n",
            "Collecting bert-score==0.3.13\n",
            "  Using cached bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "Collecting blis==0.7.9\n",
            "  Using cached blis-0.7.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "Collecting cachetools==5.3.0\n",
            "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting cachier==2.0.0\n",
            "  Using cached cachier-2.0.0-py2.py3-none-any.whl (17 kB)\n",
            "Collecting catalogue==1.0.2\n",
            "  Using cached catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting cffi==1.15.1\n",
            "  Using cached cffi-1.15.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "Collecting charset-normalizer==3.0.1\n",
            "  Using cached charset_normalizer-3.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n",
            "Collecting click==8.1.3\n",
            "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
            "Collecting cloudpickle==2.2.1\n",
            "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Collecting cma==3.3.0\n",
            "  Using cached cma-3.3.0-py3-none-any.whl (260 kB)\n",
            "Collecting colorama==0.4.6\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting contourpy==1.0.7\n",
            "  Using cached contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "Collecting cycler==0.11.0\n",
            "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting cymem==2.0.7\n",
            "  Using cached cymem-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n",
            "Collecting cython==0.29.33\n",
            "  Using cached Cython-0.29.33-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "Collecting dataclasses==0.6\n",
            "  Using cached dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting dill==0.3.6\n",
            "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "Collecting editdistance==0.6.2\n",
            "  Using cached editdistance-0.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
            "Collecting fairseq==0.10.2\n",
            "  Using cached fairseq-0.10.2-cp38-cp38-manylinux1_x86_64.whl (1.7 MB)\n",
            "Collecting faiss-gpu==1.7.2\n",
            "  Using cached faiss_gpu-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "Collecting filelock==3.9.0\n",
            "  Using cached filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
            "Collecting fonttools==4.38.0\n",
            "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "Collecting gitdb==4.0.10\n",
            "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "Collecting gitpython==3.1.31\n",
            "  Using cached GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "Collecting huggingface==0.0.1\n",
            "  Using cached huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n",
            "Collecting huggingface-hub==0.12.1\n",
            "  Using cached huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "Collecting hydra-core==1.3.2\n",
            "  Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "Collecting idna==3.4\n",
            "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
            "Collecting imohash==1.0.4\n",
            "  Using cached imohash-1.0.4-py2.py3-none-any.whl (8.4 kB)\n",
            "Collecting importlib-resources==5.12.0\n",
            "  Using cached importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting joblib==1.2.0\n",
            "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "Collecting kenlm==0.0.0\n",
            "  Using cached kenlm-0.tar.gz (1.4 MB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting kiwisolver==1.4.4\n",
            "  Using cached kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "Collecting levenshtein==0.20.9\n",
            "  Using cached Levenshtein-0.20.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (174 kB)\n",
            "Collecting lxml==4.9.2\n",
            "  Using cached lxml-4.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.1 MB)\n",
            "Collecting matplotlib==3.6.0\n",
            "  Using cached matplotlib-3.6.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "Requirement already satisfied: mmh3==3.0.0 in /usr/local/envs/test38/lib/python3.8/site-packages (from -r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 39)) (3.0.0)\n",
            "Collecting murmurhash==1.0.9\n",
            "  Using cached murmurhash-1.0.9-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
            "Collecting networkx==2.4\n",
            "  Using cached networkx-2.4-py3-none-any.whl (1.6 MB)\n",
            "Collecting nevergrad==0.4.0.post3\n",
            "  Using cached nevergrad-0.4.0.post3-py3-none-any.whl (250 kB)\n",
            "Collecting nltk==3.8.1\n",
            "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "Collecting numpy==1.19.5\n",
            "  Using cached numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
            "Collecting omegaconf==2.3.0\n",
            "  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Collecting packaging==23.0\n",
            "  Using cached packaging-23.0-py3-none-any.whl (42 kB)\n",
            "Collecting pandas==1.4.0\n",
            "  Using cached pandas-1.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "Requirement already satisfied: pathtools==0.1.2 in /usr/local/envs/test38/lib/python3.8/site-packages (from -r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 48)) (0.1.2)\n",
            "Collecting pillow==9.4.0\n",
            "  Using cached Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "Requirement already satisfied: plac==1.1.3 in /usr/local/envs/test38/lib/python3.8/site-packages (from -r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 50)) (1.1.3)\n",
            "Collecting plotly==5.13.1\n",
            "  Using cached plotly-5.13.1-py2.py3-none-any.whl (15.2 MB)\n",
            "Collecting portalocker==2.7.0\n",
            "  Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting preshed==3.0.8\n",
            "  Using cached preshed-3.0.8-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "Collecting protobuf==3.20.0\n",
            "  Using cached protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "Collecting pycparser==2.21\n",
            "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "Collecting pyparsing==3.0.9\n",
            "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "Collecting python-dateutil==2.8.2\n",
            "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "Collecting python-levenshtein==0.20.9\n",
            "  Using cached python_Levenshtein-0.20.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: pytz==2022.7.1 in /usr/local/envs/test38/lib/python3.8/site-packages (from -r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 59)) (2022.7.1)\n",
            "Collecting pyyaml==6.0\n",
            "  Using cached PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
            "Collecting rapidfuzz==2.13.7\n",
            "  Using cached rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "Collecting regex==2022.10.31\n",
            "  Using cached regex-2022.10.31-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
            "Collecting requests==2.28.2\n",
            "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "Collecting sacrebleu==2.3.1\n",
            "  Using cached sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "Collecting sacremoses==0.0.53\n",
            "  Using cached sacremoses-0.0.53-py3-none-any.whl\n",
            "Collecting scikit-learn==1.2.1\n",
            "  Using cached scikit_learn-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "Collecting scipy==1.10.1\n",
            "  Using cached scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "Collecting seaborn==0.12.2\n",
            "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "Requirement already satisfied: sentencepiece==0.1.97 in /usr/local/envs/test38/lib/python3.8/site-packages (from -r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 69)) (0.1.97)\n",
            "Collecting simalign==0.3\n",
            "  Using cached simalign-0.3-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: sklearn==0.0.post1 in /usr/local/envs/test38/lib/python3.8/site-packages (from -r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 71)) (0.0.post1)\n",
            "Collecting smmap==5.0.0\n",
            "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting spacy==2.3.9\n",
            "  Using cached spacy-2.3.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.0 MB)\n",
            "Collecting srsly==1.0.6\n",
            "  Using cached srsly-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
            "Collecting stanfordnlp==0.2.0\n",
            "  Using cached stanfordnlp-0.2.0-py3-none-any.whl (158 kB)\n",
            "Collecting submitit==1.4.5\n",
            "  Using cached submitit-1.4.5-py3-none-any.whl (73 kB)\n",
            "Collecting tabulate==0.9.0\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting tenacity==8.2.1\n",
            "  Using cached tenacity-8.2.1-py3-none-any.whl (24 kB)\n",
            "Collecting thinc==7.4.6\n",
            "  Using cached thinc-7.4.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Collecting threadpoolctl==3.1.0\n",
            "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tokenizers==0.13.2 in /usr/local/envs/test38/lib/python3.8/site-packages (from -r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 81)) (0.13.2)\n",
            "Collecting torch\n",
            "  Using cached torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
            "Collecting tqdm==4.64.1\n",
            "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "Collecting transformers==4.26.1\n",
            "  Using cached transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "Collecting transliterate==1.10.2\n",
            "  Using cached transliterate-1.10.2-py2.py3-none-any.whl (45 kB)\n",
            "Collecting truecase==0.0.14\n",
            "  Using cached truecase-0.0.14-py3-none-any.whl (28.4 MB)\n",
            "Collecting typing-extensions==4.5.0\n",
            "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting urllib3==1.26.14\n",
            "  Using cached urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "Requirement already satisfied: varint==1.0.2 in /usr/local/envs/test38/lib/python3.8/site-packages (from -r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 89)) (1.0.2)\n",
            "Requirement already satisfied: wasabi==0.10.1 in /usr/local/envs/test38/lib/python3.8/site-packages (from -r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 90)) (0.10.1)\n",
            "Collecting watchdog==2.3.0\n",
            "  Using cached watchdog-2.3.0-py3-none-manylinux2014_x86_64.whl (80 kB)\n",
            "Collecting zipp==3.15.0\n",
            "  Using cached zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/envs/test38/lib/python3.8/site-packages (from networkx==2.4->-r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 41)) (5.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/envs/test38/lib/python3.8/site-packages (from python-dateutil==2.8.2->-r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 57)) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/test38/lib/python3.8/site-packages (from requests==2.28.2->-r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 63)) (2022.12.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/test38/lib/python3.8/site-packages (from spacy==2.3.9->-r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 73)) (65.6.3)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91\n",
            "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3\n",
            "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58\n",
            "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "Collecting sympy\n",
            "  Using cached sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91\n",
            "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "Collecting jinja2\n",
            "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
            "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
            "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "Collecting triton==2.0.0\n",
            "  Using cached triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
            "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "Requirement already satisfied: wheel in /usr/local/envs/test38/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 82)) (0.38.4)\n",
            "Collecting cmake\n",
            "  Using cached cmake-3.26.0-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
            "Requirement already satisfied: lit in /usr/local/envs/test38/lib/python3.8/site-packages (from triton==2.0.0->torch->-r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 82)) (16.0.0)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Using cached MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/envs/test38/lib/python3.8/site-packages (from sympy->torch->-r /content/drive/MyDrive/AI539MUSSLT/condaenv.u7ynrrr6.requirements.txt (line 82)) (1.3.0)\n",
            "Building wheels for collected packages: kenlm\n",
            "  Building wheel for kenlm (setup.py): started\n",
            "  Building wheel for kenlm (setup.py): finished with status 'error'\n",
            "  Running setup.py clean for kenlm\n",
            "Failed to build kenlm\n",
            "Installing collected packages: kenlm, huggingface, faiss-gpu, dataclasses, cymem, cmake, charset-normalizer, antlr4-python3-runtime, zipp, watchdog, urllib3, typing-extensions, transliterate, tqdm, threadpoolctl, tenacity, tabulate, sympy, srsly, smmap, regex, rapidfuzz, pyyaml, python-dateutil, pyparsing, pycparser, protobuf, portalocker, pillow, packaging, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, murmurhash, MarkupSafe, lxml, kiwisolver, joblib, imohash, idna, fonttools, filelock, editdistance, dill, cython, cycler, colorama, cloudpickle, click, catalogue, cachetools, submitit, scipy, sacremoses, sacrebleu, requests, preshed, plotly, pandas, omegaconf, nvidia-cusolver-cu11, nvidia-cudnn-cu11, nltk, levenshtein, jinja2, importlib-resources, gitdb, contourpy, cma, cffi, cachier, blis, truecase, thinc, scikit-learn, python-levenshtein, matplotlib, hydra-core, huggingface-hub, gitpython, transformers, spacy, seaborn, bayesian-optimization, nevergrad, triton, torch, stanfordnlp, simalign, fairseq, bert-score\n",
            "  Running setup.py install for kenlm: started\n",
            "  Running setup.py install for kenlm: finished with status 'error'\n",
            "\n",
            "Pip subprocess error:\n",
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  Ã— python setup.py bdist_wheel did not run successfully.\n",
            "  â”‚ exit code: 1\n",
            "  â•°â”€> See above for output.\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for kenlm\n",
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  Ã— Running setup.py install for kenlm did not run successfully.\n",
            "  â”‚ exit code: 1\n",
            "  â•°â”€> See above for output.\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: legacy-install-failure\n",
            "\n",
            "Ã— Encountered error while trying to install package.\n",
            "â•°â”€> kenlm\n",
            "\n",
            "note: This is an issue with the package mentioned above, not pip.\n",
            "hint: See above for output from the failure.\n",
            "\n",
            "\b\bfailed\n",
            "\n",
            "CondaEnvException: Pip failed\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#!pip install torch==1.7.1\n",
        "#!pip install editdistance\n",
        "\n",
        "\n",
        "#!pip install fairseq==0.10.2\n",
        "#!pip install transformers"
      ],
      "metadata": {
        "id": "HU4gYDBSI6g_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from transformers import BartForConditionalGeneration"
      ],
      "metadata": {
        "id": "f1LFY-XJJPCv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Tfs7VMQ6Iase"
      },
      "outputs": [],
      "source": [
        "def get_model_sparsity(model: nn.Module) -> float:\n",
        "    \"\"\"\n",
        "    calculate the sparsity of the given model\n",
        "        sparsity = #zeros / #elements = 1 - #nonzeros / #elements\n",
        "    \"\"\"\n",
        "    num_nonzeros, num_elements = 0, 0\n",
        "    for param in model.parameters():\n",
        "        num_nonzeros += param.count_nonzero()\n",
        "        num_elements += param.numel()\n",
        "    return 1 - float(num_nonzeros) / num_elements\n",
        "\n",
        "def get_num_parameters(model: nn.Module, count_nonzero_only=False) -> int:\n",
        "    \"\"\"\n",
        "    calculate the total number of parameters of model\n",
        "    :param count_nonzero_only: only count nonzero weights\n",
        "    \"\"\"\n",
        "    num_counted_elements = 0\n",
        "    for param in model.parameters():\n",
        "        if count_nonzero_only:\n",
        "            num_counted_elements += param.count_nonzero()\n",
        "        else:\n",
        "            num_counted_elements += param.numel()\n",
        "    return num_counted_elements\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch.nn.utils.prune as prune\n",
        "import copy\n",
        "def get_weight_parameters(layer):\n",
        "    '''\n",
        "    Get all parameters/modules identified as 'weight'\n",
        "    '''\n",
        "    weight_parameters = []\n",
        "    if len(list(layer.children())) > 0:\n",
        "        for child in layer.children():\n",
        "            for param in child.named_parameters():\n",
        "                if 'weight' == param[0]:\n",
        "                    weight_parameters.append((child, param[0]))\n",
        "            weight_parameters.extend(get_weight_parameters(child))\n",
        "    \n",
        "    \n",
        "    return weight_parameters\n",
        "\n",
        "\n",
        "def prune_weight_parameters(model, prune_amount):\n",
        "    '''\n",
        "    Global pruning\n",
        "    '''\n",
        "    params_to_prune = get_weight_parameters(model)\n",
        "  \n",
        "    prune.global_unstructured(\n",
        "        params_to_prune, \n",
        "        pruning_method=prune.L1Unstructured, \n",
        "        amount=prune_amount,\n",
        "    )\n",
        "\n",
        "    for module, name in params_to_prune:\n",
        "        try:\n",
        "            prune.remove(module, name)\n",
        "            #print(module)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "    return model\n",
        "\n",
        "def get_pruned_models(model, sparsity):\n",
        "    model_to_prune = copy.deepcopy(model)\n",
        "    pruned_model = prune_weight_parameters(model, sparsity)\n",
        "    return pruned_model"
      ],
      "metadata": {
        "id": "jNEbmCHceUpy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model in fairseq\n",
        "from fairseq.models.bart import BARTModel\n",
        "bart = BARTModel.from_pretrained('drive/MyDrive/AI539MUSSLT/bart.base', checkpoint_file='checkpoint_best.pt')\n",
        "bart.eval()  # disable dropout (or leave in train mode to finetune)"
      ],
      "metadata": {
        "id": "c4qzxJdoI1gY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "edaaa675-5311-4201-8455-c18ccb5dec95"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-251df7ce2d7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the model in fairseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfairseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbart\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBARTModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBARTModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/AI539MUSSLT/bart.base'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'checkpoint_best.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# disable dropout (or leave in train mode to finetune)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fairseq'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for module_name, module in bart.named_modules():\n",
        "  print(module_name)"
      ],
      "metadata": {
        "id": "UQAzgV4nxJlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bart.fill_mask(['The cat <mask> on the <mask> .'], topk=3, beam=10)"
      ],
      "metadata": {
        "id": "ooNwTF4UMHWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_model_sparsity(bart.model)"
      ],
      "metadata": {
        "id": "2EwkkYJgMTvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bart_total_params = sum(p.numel() for p in bart.parameters() if p.requires_grad)\n",
        "bart_total_params"
      ],
      "metadata": {
        "id": "0qKANsyOPSdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bart_pruned = get_pruned_models(bart.model, 0.1)\n",
        "print(get_model_sparsity(bart_pruned))\n",
        "for i in range(2):\n",
        "  bart_pruned = get_pruned_models(bart_pruned, 0.1*(i+1))\n",
        "  print(get_model_sparsity(bart_pruned))"
      ],
      "metadata": {
        "id": "gSXzSgNJfNNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(bart_pruned.state_dict(), '/content/test.pt')"
      ],
      "metadata": {
        "id": "ZcG2Sf0tfYAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BARTModel.from_pretrained('drive/MyDrive/AI539MUSSLT/bart.base', checkpoint_file='checkpoint_best.pt')\n",
        "model.model.load_state_dict(torch.load('/content/test.pt'), strict=False)\n",
        "\n",
        "model.eval()\n",
        "get_model_sparsity(model)\n"
      ],
      "metadata": {
        "id": "x3PXqpNVjnef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/drive/MyDrive/AI539MUSSLT/fairseq_models/checkpoint_6_40000.pt\n",
        "model = BARTModel.from_pretrained('drive/MyDrive/AI539MUSSLT/bart.base', checkpoint_file='checkpoint_best.pt')\n",
        "model.model.load_state_dict(torch.load('/content/drive/MyDrive/AI539MUSSLT/fairseq_models/checkpoint_6_40000.pt'), strict=False)\n",
        "\n",
        "model.eval()\n",
        "get_model_sparsity(model)"
      ],
      "metadata": {
        "id": "_pMxb9gnWxXO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}